# Poorman's AR-DiT TTS ğŸ“¢

> **å…³é”®è¯**: ARDiT, AR-DiT, Autoregressive Diffusion Transformer, TTS, Text-to-Speech, Mel-Spectrogram

å— AR-DiT (ARDiT) å¯å‘çš„**ä½èµ„æºå‹å¥½**è¯­éŸ³åˆæˆç³»ç»Ÿï¼Œé‡‡ç”¨è‡ªå›å½’ Transformerï¼ˆQwen3 LLMï¼‰+ æ‰©æ•£æ¨¡å‹çš„æ¶æ„ï¼Œé€šè¿‡æ‰©æ•£è¿‡ç¨‹ç”Ÿæˆ Mel é¢‘è°±ï¼Œå†ç» Vocoder è½¬æ¢ä¸ºéŸ³é¢‘ã€‚

**âœ¨ æœ€å°å®ç°çš„ AR-DiT TTS è®­ç»ƒæ¨ç† Pipeline**ï¼Œå¯åœ¨å•å¼  RTX 5090 (32GB) ä¸Šä½¿ç”¨ 8000 å°æ—¶æ•°æ®é›†ï¼Œä¸¤å¤©å†…è®­ç»ƒå‡ºå¯æ‡‚çš„è¯­éŸ³åˆæˆç»“æœã€‚

> **PS**: Diffusion backbone ä½¿ç”¨çš„æ˜¯ [RFWave](https://github.com/bfs18/rfwave) çš„ ConvNeXt æ¶æ„ï¼Œè€Œé DiTã€‚

## ğŸŒŸ ä¸ºä»€ä¹ˆé€‰æ‹©æœ¬é¡¹ç›®ï¼Ÿ

- ğŸš€ **ä½èµ„æºå‹å¥½**ï¼šå•å¡ RTX 5090 (32GB) å³å¯å¤„ç† 8000 å°æ—¶æ•°æ®é›†è®­ç»ƒ
- ğŸ“¦ **æœ€å°å®ç°**ï¼šä»£ç ç®€æ´æ¸…æ™°ï¼Œæ˜“äºç†è§£å’Œä¿®æ”¹ï¼Œé€‚åˆå­¦ä¹ å’ŒäºŒæ¬¡å¼€å‘
- ğŸ‡¨ğŸ‡³ **ä¸­æ–‡å‹å¥½**ï¼šå®Œæ•´çš„ä¸­æ–‡æ–‡æ¡£å’Œä¸­æ–‡æ•°æ®å¤„ç†æµç¨‹
- ğŸ¤— **å¼€ç®±å³ç”¨**ï¼šæä¾›é¢„è®­ç»ƒæ¨¡å‹å’Œå¤„ç†å¥½çš„æ•°æ®é›†ï¼Œå¿«é€Ÿä¸Šæ‰‹
- ğŸ’¡ **å®ç”¨å¯¼å‘**ï¼šä¸¤å¤©è®­ç»ƒå³å¯è¾¾åˆ°å¯æ‡‚æ•ˆæœï¼Œè®­ç»ƒæ›´ä¹…è´¨é‡æ›´å¥½ - practical rather than perfect

## ğŸµ ç”Ÿæˆç¤ºä¾‹

è®­ç»ƒæ¨¡å‹ç”Ÿæˆçš„éŸ³é¢‘ç¤ºä¾‹ï¼š

<audio controls>
  <source src="outputs/inference_audio_203019_796b492db63e5ccaad85.wav" type="audio/wav">
  æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾ã€‚<a href="outputs/inference_audio_203019_796b492db63e5ccaad85.wav">ä¸‹è½½éŸ³é¢‘</a>
</audio>

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ¤— Hugging Face èµ„æº

æˆ‘ä»¬åœ¨ Hugging Face ä¸Šæä¾›äº†é¢„è®­ç»ƒæ¨¡å‹å’Œè®­ç»ƒæ•°æ®é›†ï¼š

- **é¢„è®­ç»ƒæ¨¡å‹**: [laupeng1989/armel-checkpoint](https://huggingface.co/laupeng1989/armel-checkpoint)
- **è®­ç»ƒæ•°æ®é›†**: [laupeng1989/armel-dataset](https://huggingface.co/datasets/laupeng1989/armel-dataset)

ä¸‹è½½èµ„æºï¼š
```bash
# ä¸‹è½½è®­ç»ƒæ•°æ®é›†
huggingface-cli download laupeng1989/armel-dataset --repo-type dataset --local-dir ./data/armel-dataset

# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
huggingface-cli download laupeng1989/armel-checkpoint --local-dir ./models/armel-checkpoint
```

**ğŸ’¡ æç¤º**ï¼šå¦‚æœä½¿ç”¨ Hugging Face ä¸Šçš„æ•°æ®é›†ï¼Œå¯ä»¥è·³è¿‡ä¸‹é¢çš„"æ•°æ®å‡†å¤‡"ç¯èŠ‚ï¼Œç›´æ¥è¿›å…¥è®­ç»ƒæ­¥éª¤ã€‚

## ğŸ“Š æ•°æ®å‡†å¤‡

### 1ï¸âƒ£ å‡†å¤‡åŸå§‹æ•°æ®

æœ¬é¡¹ç›®ä½¿ç”¨ [Amphion Emilia é¢„å¤„ç†å™¨](https://github.com/open-mmlab/Amphion/tree/main/preprocessors/Emilia) å¤„ç†åŸå§‹éŸ³é¢‘æ•°æ®ã€‚

å¤„ç†åçš„æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼š
```
example_data/
â”œâ”€â”€ ä»™é€† ç¬¬87é›† èº«ä¸–è‹é†’ï¼ˆä¸‹ï¼‰ [638031163].json
â”œâ”€â”€ ä»™é€† ç¬¬87é›† èº«ä¸–è‹é†’ï¼ˆä¸‹ï¼‰ [638031163]_000000.m4a
â”œâ”€â”€ ä»™é€† ç¬¬87é›† èº«ä¸–è‹é†’ï¼ˆä¸‹ï¼‰ [638031163]_000001.m4a
â”œâ”€â”€ ä»™é€† ç¬¬87é›† èº«ä¸–è‹é†’ï¼ˆä¸‹ï¼‰ [638031163]_000002.m4a
â””â”€â”€ ...
```

JSON æ–‡ä»¶æ ¼å¼ï¼ˆåŒ…å«åˆ†æ®µä¿¡æ¯å’Œæ–‡æœ¬ï¼‰ï¼š
```json
[
  {
    "duration": 10.94,
    "text": "[SPEAKER_00] æ¬¢è¿æ”¶å¬...",
    "speaker": 0,
    "parts": [
      {
        "text": "[SPEAKER_00] æ¬¢è¿æ”¶å¬...",
        "start": 4.5125,
        "end": 10.1525,
        "speaker": 0,
        "language": "zh"
      }
    ]
  }
]
```

### 2ï¸âƒ£ æ„å»ºè®­ç»ƒæ•°æ®é›†

ä½¿ç”¨ `build_dataset.py` å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼ï¼š

```bash
python scripts/build_dataset.py \
  --data_dir <your_raw_data_dir> \
  --output_dir <your_output_dir> \
  --num_proc 8 \
  --test_samples 100 \
  --random_seed 42
```

**å‚æ•°è¯´æ˜**ï¼š
- `--data_dir`: åŸå§‹æ•°æ®ç›®å½•ï¼ˆåŒ…å« Emilia é¢„å¤„ç†åçš„ .json å’Œ .m4a æ–‡ä»¶ï¼‰
- `--output_dir`: è¾“å‡ºç›®å½•ï¼Œä¼šè‡ªåŠ¨åˆ›å»º `train/` å’Œ `test/` å­ç›®å½•
- `--num_proc`: å¹¶è¡Œå¤„ç†è¿›ç¨‹æ•°
- `--test_samples`: æµ‹è¯•é›†æ ·æœ¬æ•°é‡
- `--random_seed`: éšæœºç§å­

## ğŸ”¥ è®­ç»ƒ

### ğŸ’» è®­ç»ƒç¡¬ä»¶

æœ¬é¡¹ç›®åœ¨ **NVIDIA RTX 5090 (32GB)** ä¸Šè®­ç»ƒã€‚

### âš¡ è®­ç»ƒå‘½ä»¤

**å‡†å¤‡ Qwen3 æ¨¡å‹**ï¼š

`model.llm_model_path` å¯ä»¥æ˜¯ï¼š
- **æœ¬åœ°è·¯å¾„**ï¼šå¦‚ `./Qwen3-0.6B`ï¼ˆéœ€æå‰ä¸‹è½½ï¼‰
- **Hugging Face æ¨¡å‹å**ï¼šå¦‚ `Qwen/Qwen3-0.6B`ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œä½†é¦–æ¬¡è®­ç»ƒä¼šè¾ƒæ…¢ï¼‰

æ¨èæå‰ä¸‹è½½åˆ°æœ¬åœ°ï¼š
```bash
huggingface-cli download Qwen/Qwen3-0.6B --local-dir ./Qwen3-0.6B
```

**è®­ç»ƒå‘½ä»¤**ï¼š

```bash
python3 scripts/mel_train.py \
  dataset.train_dataset_path=<your_train_data_path> \
  dataset.valid_dataset_path=<your_valid_data_path> \
  model.llm_model_path=./Qwen3-0.6B \
  model.rfmel.batch_mul=2 \
  training.batch_size=4 \
  dataset.max_tokens=1024 \
  training.num_workers=16 \
  training.learning_rate=0.0001 \
  training.log_dir=<your_log_dir> \
  training.diffusion_extra_steps=4 \
  training.check_val_every_n_epoch=1 \
  model.use_skip_connection=true \
  model.estimator.hidden_dim=512 \
  model.estimator.intermediate_dim=1536 \
  model.estimator.num_layers=8
```

### ğŸš„ å¤šå¡è®­ç»ƒ

```bash
# ä½¿ç”¨ 2 å¼  GPU
CUDA_VISIBLE_DEVICES=0,1 python3 scripts/mel_train.py \
  dataset.train_dataset_path=<your_train_data_path> \
  dataset.valid_dataset_path=<your_valid_data_path> \
  model.llm_model_path=Qwen3-0.6B \
  model.rfmel.batch_mul=2 \
  training.batch_size=8 \
  dataset.max_tokens=1024 \
  training.num_workers=16 \
  training.learning_rate=0.0001 \
  training.log_dir=<your_log_dir> \
  training.diffusion_extra_steps=4 \
  training.check_val_every_n_epoch=1 \
  model.use_skip_connection=true \
  model.estimator.hidden_dim=512 \
  model.estimator.intermediate_dim=1536 \
  model.estimator.num_layers=8
```

**æ³¨æ„**ï¼š
- Lightning ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æ‰€æœ‰å¯ç”¨ GPUï¼Œä½¿ç”¨ DDP ç­–ç•¥
- æ ¹æ®æ‚¨çš„ç¡¬ä»¶é…ç½®ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ `batch_size`ã€`batch_mul`ã€`max_tokens` ç­‰å‚æ•°

## ğŸ“¤ å¯¼å‡ºæ¨¡å‹

è®­ç»ƒå®Œæˆåï¼Œå¯¼å‡ºæ¨¡å‹ç”¨äºæ¨ç†ï¼š

```bash
python scripts/mel_export_checkpoint.py \
  --ckpt_path <your_checkpoint_path>/last.ckpt \
  --output_path ./exported_model/
```

æˆ–è€…ç›´æ¥æŒ‡å®š checkpoints ç›®å½•ï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€æ–°çš„ï¼‰ï¼š
```bash
python scripts/mel_export_checkpoint.py \
  --ckpt_path <your_checkpoint_dir>/ \
  --output_path ./exported_model/
```

å¯¼å‡ºåä¼šç”Ÿæˆï¼š
- `model.ckpt`: æ¨¡å‹æƒé‡
- `model.yaml`: æ¨ç†é…ç½®

## ğŸ¤ æ¨ç†

```bash
python3 scripts/mel_inference.py \
  --model_path <your_model_dir>/ \
  --text example_data/transcript/fanren_short.txt \
  --ref_audio fanren08 \
  --output_path output/generated \
  --dtype bfloat16
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `output/generated.wav`: ç”Ÿæˆçš„éŸ³é¢‘
- `output/generated.png`: Mel é¢‘è°±å›¾
- `output/generated.npy`: Mel é¢‘è°±æ•°ç»„

### ğŸ§ å‚è€ƒéŸ³é¢‘è¯´æ˜

`--ref_audio` å‚æ•°æŒ‡å®šå‚è€ƒéŸ³é¢‘çš„åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œè„šæœ¬ä¼šä» `example_data/voice_prompts/` ç›®å½•è¯»å–å¯¹åº”çš„ `.wav` å’Œ `.txt` æ–‡ä»¶ï¼š

```
example_data/voice_prompts/
â”œâ”€â”€ fanren08.wav          # å‚è€ƒéŸ³é¢‘
â”œâ”€â”€ fanren08.txt          # å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬
â”œâ”€â”€ fanren09.wav
â””â”€â”€ fanren09.txt
```

å¯ä»¥æ·»åŠ è‡ªå·±çš„å‚è€ƒéŸ³é¢‘ï¼Œåªéœ€å°†éŸ³é¢‘æ–‡ä»¶å’Œå¯¹åº”çš„æ–‡æœ¬æ–‡ä»¶æ”¾å…¥è¯¥ç›®å½•å³å¯ã€‚

### âš™ï¸ å‚æ•°è¯´æ˜

- `--model_path`: å¯¼å‡ºçš„æ¨¡å‹ç›®å½•æˆ– .ckpt æ–‡ä»¶è·¯å¾„
- `--text`: è¦åˆæˆçš„æ–‡æœ¬ï¼Œæˆ–æ–‡æœ¬æ–‡ä»¶è·¯å¾„
- `--ref_audio`: å‚è€ƒéŸ³é¢‘åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œå¯ç”¨é€—å·åˆ†éš”å¤šä¸ª
- `--output_path`: è¾“å‡ºæ–‡ä»¶è·¯å¾„å‰ç¼€ï¼ˆä¼šç”Ÿæˆ .wav, .png, .npy ä¸‰ä¸ªæ–‡ä»¶ï¼‰
- `--dtype`: æ•°æ®ç±»å‹ï¼ˆfloat32/float16/bfloat16ï¼Œé»˜è®¤ bfloat16ï¼‰
- `--device`: è®¾å¤‡ï¼ˆcuda/cpu/mpsï¼Œé»˜è®¤ cudaï¼‰
- `--temperature`: é‡‡æ ·æ¸©åº¦ï¼ˆé»˜è®¤ 0.7ï¼‰
- `--top_p`: Top-p é‡‡æ ·ï¼ˆé»˜è®¤ 0.7ï¼‰
- `--max_new_tokens`: æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆé»˜è®¤ 1024ï¼‰
- `--chunk_method`: æ–‡æœ¬åˆ†å—æ–¹æ³•ï¼ˆspeaker/word/noneï¼Œé»˜è®¤ speakerï¼‰
- `--seed`: éšæœºç§å­ï¼ˆé»˜è®¤ 42ï¼‰

## ğŸ“ é¡¹ç›®ç»“æ„

```
ar-dit-mel/
â”œâ”€â”€ ar/                      # è‡ªå›å½’æ¨¡å‹
â”‚   â”œâ”€â”€ armel.py            # ARMel ä¸»æ¨¡å‹
â”‚   â”œâ”€â”€ qwen.py             # Qwen3 LLM
â”‚   â””â”€â”€ mel_generate.py     # Mel ç”Ÿæˆ
â”œâ”€â”€ rfwave/                  # æ‰©æ•£æ¨¡å‹
â”‚   â”œâ”€â”€ mel_model.py        # RFMel æ¨¡å‹
â”‚   â”œâ”€â”€ mel_processor.py    # Mel å¤„ç†å™¨
â”‚   â””â”€â”€ estimator.py        # æ‰©æ•£ Estimator
â”œâ”€â”€ dataset/                 # æ•°æ®é›†
â”œâ”€â”€ scripts/                 # è®­ç»ƒå’Œæ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ build_dataset.py    # æ„å»ºæ•°æ®é›†
â”‚   â”œâ”€â”€ mel_train.py        # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ mel_export_checkpoint.py  # å¯¼å‡ºæ¨¡å‹
â”‚   â””â”€â”€ mel_inference.py    # æ¨ç†è„šæœ¬
â””â”€â”€ configs/                 # é…ç½®æ–‡ä»¶
```

## ğŸ“œ è®¸å¯è¯

MIT License

## ğŸ“š ç›¸å…³è®ºæ–‡

- **Autoregressive Diffusion Transformer for Text-to-Speech Synthesis**
  Zhijun Liu, et al.
  [arXiv:2406.05551](https://arxiv.org/abs/2406.05551)

- **VibeVoice Technical Report**
  Zhiliang Peng, et al.
  [arXiv:2508.19205](https://arxiv.org/abs/2508.19205)

- **VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning**
  Yixuan Zhou, et al.
  [arXiv:2509.24650](https://arxiv.org/abs/2509.24650)

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š
- [Qwen3](https://github.com/QwenLM/Qwen) - è¯­è¨€æ¨¡å‹ ğŸ¤–
- [Amphion](https://github.com/open-mmlab/Amphion) - æ•°æ®é¢„å¤„ç† ğŸµ
- [Vocos](https://github.com/gemelo-ai/vocos) - Vocoder ğŸ”Š
- [RFWave](https://github.com/bfs18/rfwave) - Diffusion Backbone ğŸŒŠ
- [VoxCPM](https://github.com/OpenBMB/VoxCPM) - æ¶æ„å‚è€ƒ ğŸ’¡
- [Higgs-Audio](https://github.com/boson-ai/higgs-audio) - æ•°æ®æ¨¡æ¿ ğŸ“‹

